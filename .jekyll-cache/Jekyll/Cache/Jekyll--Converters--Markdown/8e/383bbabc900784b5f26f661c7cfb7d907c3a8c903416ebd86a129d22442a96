I"ùL<!-- _pages/publications.md -->
<div class="publications">
For the most up-to-date list, please refer to my <a href="https://scholar.google.com/citations?user=V-guxukAAAAJ">Google Scholar</a>.
  <h2 class="year">2022</h2>
  <ol class="bibliography"></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021domain" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Domain Invariant Representation Learning with Domain Density Transformations</div>
          <!-- Author -->
          <div class="author">
                  <em>Nguyen, A. Tuan</em>,&nbsp;Tran, Toan,&nbsp;<a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/">Gal, Yarin</a>,&nbsp;and <a href="https://gbaydin.github.io/">Baydin, Atƒ±lƒ±m G√ºne≈ü</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems 35 (NeurIPS)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://papers.nips.cc/paper/2021/hash/2a2717956118b4d223ceca17ce3865e2-Abstract.html" class="btn btn-sm z-depth-0" role="button">HTML</a>
            <a href="/assets/pdf/NeurIPS_nguyen2021domain.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Domain generalization refers to the problem where we aim to train a model on
data from a set of source domains so that the model can generalize to unseen target
domains. Naively training a model on the aggregate set of data (pooled from all
source domains) has been shown to perform suboptimally, since the information
learned by that model might be domain-specific and generalize imperfectly to target
domains. To tackle this problem, a predominant domain generalization approach
is to learn some domain-invariant information for the prediction task, aiming at
a good generalization across domains. In this paper, we propose a theoretically
grounded method to learn a domain-invariant representation by enforcing the
representation network to be invariant under all transformation functions among
domains. We next introduce the use of generative adversarial networks to learn such
domain transformations in a possible implementation of our method in practice.
We demonstrate the effectiveness of our method on several widely used datasets for
the domain generalization problem, on all of which we achieve competitive results
with state-of-the-art models.</p>
          </div><!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2021domain</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{NeurIPS_nguyen2021domain.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://papers.nips.cc/paper/2021/hash/2a2717956118b4d223ceca17ce3865e2-Abstract.html}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Domain Invariant Representation Learning with Domain Density Transformations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Tran, Toan and Gal, Yarin and Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems 35 (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021clinical" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning</div>
          <!-- Author -->
          <div class="author">
                  <em>Nguyen, A. Tuan</em>,&nbsp;Jeong, Hyewon,&nbsp;Yang, Eunho,&nbsp;and Hwang, Sung Ju
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17097" class="btn btn-sm z-depth-0" role="button">HTML</a>
            <a href="/assets/pdf/AAAI_nguyen2021clinical.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Although recent multi-task learning methods have shown to be effective in improving the generalization of deep neural networks, they should be used with caution for safety-critical applications, such as clinical risk prediction. This is because even if they achieve improved task-average performance, they may still yield degraded performance on individual tasks, which may be critical (e.g., prediction of mortality risk). Existing asymmetric multi-task learning methods tackle this negative transfer problem by performing knowledge transfer from tasks with low loss to tasks with high loss. However, using loss as a measure of reliability is risky since low loss could result from overfitting. In the case of time-series prediction tasks, knowledge learned for one task (e.g., predicting the sepsis onset) at a specific timestep may be useful for learning another task (e.g., prediction of mortality) at a later timestep, but lack of loss at each timestep makes it difficult to measure the reliability at each timestep. To capture such dynamically changing asymmetric relationships between tasks in time-series data, we propose a novel temporal asymmetric multi-task learning model that performs knowledge transfer from certain tasks/timesteps to relevant uncertain tasks, based on the feature-level uncertainty. We validate our model on multiple clinical risk prediction tasks against various deep learning models for time-series prediction, which our model significantly outperforms without any sign of negative transfer. Further qualitative analysis of learned knowledge graphs by clinicians shows that they are helpful in analyzing the predictions of the model.</p>
          </div><!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2021clinical</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AAAI}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{AAAI_nguyen2021clinical.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17097}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17097}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Jeong, Hyewon and Yang, Eunho and Hwang, Sung Ju}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9081-9091}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS ORL</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyentang2021offline" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization</div>
          <!-- Author -->
          <div class="author"><a href="https://thanhnguyentang.github.io/">Nguyen-Tang, Thanh</a>,&nbsp;Gupta, Sunil,&nbsp;
                  <em>Nguyen, A. Tuan</em>,&nbsp;and Venkatesh, Svetha
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Workshop on Offline Reinforcement Learning, NeurIPS</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://offline-rl-neurips.github.io/2021/pdf/28.pdf" class="btn btn-sm z-depth-0" role="button">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyentang2021offline</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS ORL}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://offline-rl-neurips.github.io/2021/pdf/28.pdf}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen-Tang, Thanh and Gupta, Sunil and Nguyen, A. Tuan and Venkatesh, Svetha}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Workshop on Offline Reinforcement Learning, NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">arxiv</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021kl" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">KL Guided Domain Adaptation</div>
          <!-- Author -->
          <div class="author">
                  <em>Nguyen, A Tuan</em>,&nbsp;Tran, Toan,&nbsp;<a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/">Gal, Yarin</a>,&nbsp;<a href="https://www.robots.ox.ac.uk/~phst/">Torr, Philip HS</a>,&nbsp;and <a href="https://gbaydin.github.io/">Baydin, Atƒ±lƒ±m G√ºne≈ü</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>arXiv preprint arXiv:2106.07780</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2106.07780" class="btn btn-sm z-depth-0" role="button">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Domain adaptation is an important problem and often needed for real-world ap-
plications. In this problem, instead of i.i.d. datapoints, we assume that the source
(training) data and the target (testing) data have different distributions. With that
setting, the empirical risk minimization training procedure often does not perform
well, since it does not account for the change in the distribution. A common
approach in the domain adaptation literature is to learn a representation of the input
that has the same distributions over the source and the target domain. However,
these approaches often require additional networks and/or optimizing an adversarial
(minimax) objective, which can be very expensive or unstable in practice. To tackle
this problem, we first derive a generalization bound for the target loss based on
the training loss and the reverse Kullback‚ÄìLeibler (KL) divergence between the
source and the target representation distributions. Based on this bound, we derive
an algorithm that minimizes the KL term to obtain a better generalization to the
target domain. We show that with a probabilistic representation network, the KL
term can be estimated efficiently via minibatch samples without any additional
network or a minimax objective. This leads to a theoretically sound alignment
method which is also very efficient and stable in practice. Experimental results also
suggest that our method outperforms other representation-alignment approaches.</p>
          </div><!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2021kl</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arxiv}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2106.07780}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{KL Guided Domain Adaptation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A Tuan and Tran, Toan and Gal, Yarin and Torr, Philip HS and Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2106.07780}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IEEE TMC</abbr></div>

        <!-- Entry bib key -->
        <div id="9462324" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Detection of Microsleep Events with a Behind-the-ear Wearable System</div>
          <!-- Author -->
          <div class="author">Pham, Nhat,&nbsp;Dinh, Tuan,&nbsp;Kim, Taeho,&nbsp;Raghebi, Zohreh,&nbsp;Bui, Nam,&nbsp;Truong, Hoang,&nbsp;
                  <em>Nguyen, A. Tuan</em>,&nbsp;Banaei-Kashani, Farnoush,&nbsp;Halbower, Ann,&nbsp;Dinh, Thang N.,&nbsp;Nguyen, Vp,&nbsp;and Vu, Tam
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Mobile Computing</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/9462324" class="btn btn-sm z-depth-0" role="button">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9462324</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IEEE TMC}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9462324}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat and Dinh, Tuan and Kim, Taeho and Raghebi, Zohreh and Bui, Nam and Truong, Hoang and Nguyen, A. Tuan and Banaei-Kashani, Farnoush and Halbower, Ann and Dinh, Thang N. and Nguyen, Vp and Vu, Tam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Detection of Microsleep Events with a Behind-the-ear Wearable System}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2021.3090829}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"></ol>


</div>
:ET